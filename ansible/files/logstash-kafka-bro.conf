input {
  kafka {
    topics => ["bro-raw"]
    add_field => { "[@metadata][stage]" => "broraw_kafka" }
    # Set this to one per kafka partition to scale up
    #consumer_threads => 4
    group_id => "bro_logstash"
    bootstrap_servers => "127.0.0.1:9092"
    codec => json
    auto_offset_reset => "earliest"
  }
}

filter {
  if "_jsonparsefailure" in [tags] {
    drop { }
  }

  if [@metadata][stage] == "broraw_kafka" {

    # Set the timestamp
    date { match => [ "ts", "ISO8601" ] }

    # move metadata to new field
    mutate {
      rename => {
        "@stream" => "[@meta][stream]"
        "@system" => "[@meta][system]"
        "@proc"   => "[@meta][proc]"
      }
    }

    # Rename ID field from file analyzer logs
    if [@meta][stream] in ["pe", "x509", "files"] {
      mutate { rename => { "id" => "fuid" } }
      mutate {
        add_field => { "[@meta][event_type]" => "file" }
        add_field => { "[@meta][id]" => "%{fuid}" }
      }
    } else if [@meta][stream] in ["intel", "notice", "notice_alarm", "signatures", "traceroute"] {
      mutate { add_field => { "[@meta][event_type]" => "detection" } }
    } else if [@meta][stream] in [ "capture_loss", "cluster", "communication", "loaded_scripts", "packet_filter", "prof", "reporter", "stats", "stderr", "stdout" ] {
      mutate { add_field => { "[@meta][event_type]" => "diagnostic" } }
    } else if [@meta][stream] in ["netcontrol", "netcontrol_drop", "netcontrol_shunt", "netcontrol_catch_release", "openflow"] {
      mutate { add_field => { "[@meta][event_type]" => "netcontrol" } }
    } else if [@meta][stream] in ["known_certs", "known_devices", "known_hosts", "known_modbus", "known_services", "software"] {
      mutate { add_field => { "[@meta][event_type]" => "observations" } }
    } else if [@meta][stream] in ["barnyard2", "dpd", "unified2", "weird"] {
      mutate { add_field => { "[@meta][event_type]" => "miscellaneous" } }
    } else {
      # Network type
      mutate {
        add_field => { "[@meta][event_type]" => "network" }
        add_field => { "[@meta][id]" => "%{uid}" }
        add_field => { "id_orig_h" => "[@meta][orig_host]" }
	      add_field => { "id_orig_p" => "[@meta][orig_port]" }
        add_field => { "id_resp_h" => "[@meta][resp_host]" }
	      add_field => { "id_resp_p" => "[@meta][resp_port]" }
      }
      geoip {
        source => "id_orig_h"
        target => "[@meta][geoip_orig]"
      }
      geoip {
        source => "id_resp_h"
        target => "[@meta][geoip_resp]"
      }

      #if [@meta][stream] in ["conn"] {
      #  translate {
      #    field => "conn_state"
      #    destination => "[@meta][conn_state_full]"
      #    dictionary => [
      #      "S0", "Connection attempt seen, no reply",
      #      "S1", "Connection established, not terminated",
      #      "S2", "Connection established and close attempt by originator seen (but no reply from responder)",
      #      "S3", "Connection established and close attempt by responder seen (but no reply from originator)",
      #      "SF", "Normal SYN/FIN completion",
      #      "REJ", "Connection attempt rejected",
      #      "RSTO", "Connection established, originator aborted (sent a RST)",
      #      "RSTR", "Established, responder aborted",
      #      "RSTOS0", "Originator sent a SYN followed by a RST, we never saw a SYN-ACK from the responder",
      #      "RSTRH", "Responder sent a SYN ACK followed by a RST, we never saw a SYN from the (purported) originator",
      #      "SH", "Originator sent a SYN followed by a FIN, we never saw a SYN ACK from the responder (hence the connection was 'half' open)",
      #      "SHR", "Responder sent a SYN ACK followed by a FIN, we never saw a SYN from the originator",
      #      "OTH", "No SYN seen, just midstream traffic (a 'partial connection' that was not later closed)"
      #    ]
      #  }
      #}
    }

    # Tie related records
    if [uid] {
      mutate { add_field => {"[@meta][related_ids]" => ["%{uid}"] } }
    } else if [fuid] and ![uid] {
      mutate { add_field => {"[@meta][related_ids]" => ["%{fuid}"] } }
    }
    if [fuid] and [uid] {
      mutate { merge => {"[@meta][related_ids]" => ["%{fuid}"] } }
    }

    mutate {
      merge => { "[@meta][related_ids]" => "related_fuids" }
      merge => { "[@meta][related_ids]" => "conn_uids" }
    }

    # Nest the entire document
    ruby {
      code => "
      require 'logstash/event'

      logtype = event.get('[@meta][stream]')
      ev_hash = event.to_hash
      meta_hash = ev_hash['@meta']
      timestamp = ev_hash['@timestamp']

      # Cleanup duplicate info
      meta_hash.delete('stream')
      ev_hash.delete('@meta')
      ev_hash.delete('@timestamp')
      ev_hash.delete('tags')

      result = {
        logtype => ev_hash,
        '@meta' => meta_hash,
        '@timestamp' => timestamp
      }
      event.initialize( result )
      "
    }
    mutate { add_field => {"[@metadata][stage]" => "broraw_kafka" } }
  }
}

output {
  if [@metadata][stage] == "broraw_kafka" {
    kafka {
     codec => json
     topic_id => "bro-clean"
     bootstrap_servers => "127.0.0.1:9092"
    }

    if [@meta][event_type] and [@meta][id] {
      elasticsearch {
        hosts => ["127.0.0.1"]
        index => "bro-%{+YYYY.MM.dd}"
        document_type => "%{[@meta][event_type]}"
        document_id => "%{[@meta][id]}"
      }
    } else {
      elasticsearch {
        hosts => ["127.0.0.1"]
        index => "bro-%{+YYYY.MM.dd}"
        document_type => "%{[@meta][event_type]}"
      }
    }
  }
}
